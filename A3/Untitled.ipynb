{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "def tokenize_string(my_string):\n",
    "    \"\"\" DONE. You should use this in your tokenize function.\n",
    "    \"\"\"\n",
    "    return re.findall('[\\w\\-]+', my_string.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(movies):\n",
    "    tok = []\n",
    "    col_vals = movies['genres']\n",
    "    for c in col_vals:\n",
    "        tok.append(tokenize_string(c))\n",
    "#    for t in tok:\n",
    "    movies['tokens'] = pd.Series(tok)\n",
    "    return movies\n",
    "    \n",
    "movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "#movies['movieId'].tolist()\n",
    "movies = tokenize(movies)\n",
    "#movies['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-1-d0868d876f2a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d0868d876f2a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    tf(horror,123) = 2\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "movies = pd.DataFrame([[123, 'Horror|Romance|Horror'], [456, 'Sci-Fi|Romance']], columns=['movieId', 'genres'])\n",
    "\n",
    "tf(horror,123) = 2\n",
    "tf(romance,123) = 1\n",
    "tf(romance,456) = 1 \n",
    "tf(scifi,456) = 1\n",
    "\n",
    "maxk(123) = 2\n",
    "maxk(456) = 1\n",
    "\n",
    "df(horror) = 1\n",
    "df(Romance) = 2\n",
    "df(scifi) = 1\n",
    "\n",
    "tfidf = tf(i,d) / maxk * log10(N/df(i))\n",
    "\n",
    "tfidf(horror,123) = 2/2*log10(2/1)\n",
    "tfidf(romance,123) = 1/2*log10(2/2)\n",
    "tfidf(scifi,123) = 0\n",
    "\n",
    "tfidf(horror,456) = 0\n",
    "tfidf(romance,456) = 1/1*log10(2/2)\n",
    "tfidf(scifi,456) = 1/1*log10(2/1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94392028878\n",
      "2.16024689947\n",
      "2.60906448251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([2/3,7/3,5/3])\n",
    "y = np.array([5/3, 1/3, 4/3])\n",
    "\n",
    "print(np.linalg.norm(x))\n",
    "print(np.linalg.norm(y))\n",
    "print((32/9)/np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featurize(movies):\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocabulary = {}\n",
    "    max_k = defaultdict()\n",
    "    df = dict()\n",
    "    genres = movies['tokens']\n",
    "    flat = list(set([item for sublist in genres for item in sublist]))\n",
    "    N = len(movies)\n",
    "    x = []\n",
    "    a = []\n",
    "    genres = list(genres)\n",
    "    for g in genres:\n",
    "        for f in flat:\n",
    "            if f in g:\n",
    "                x.append(f)\n",
    "    df = dict(Counter(x))\n",
    "    \n",
    "    for g in genres:\n",
    "        for vl in g:\n",
    "            a.append(vl)\n",
    "            \n",
    "    for vl in sorted(a):\n",
    "        vocabulary.setdefault(vl,len(vocabulary))\n",
    "    \n",
    "    for g in sorted(genres):\n",
    "        c = Counter(g)\n",
    "        tf = dict(c)\n",
    "        max_k = tf[max(tf.keys())]\n",
    "        unique = sorted(list(set(g)))\n",
    "        for x in unique:\n",
    "            nr = tf[x]\n",
    "            dr = max_k * np.log10(N/df[x])\n",
    "            index = vocabulary[x]\n",
    "            indices.append(index)\n",
    "            data.append(nr/dr)\n",
    "        indptr.append(len(indices))\n",
    "    csr = csr_matrix((data, indices, indptr))\n",
    "    i = 0\n",
    "    movies['features'] = \"\"\n",
    "    for i in range(len(vocabulary)-1):\n",
    "        movies.set_value(i,'features',csr.getrow(i)) \n",
    "    \n",
    "    return (movies,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "      <th>tokens</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Horror|Romance</td>\n",
       "      <td>[horror, romance]</td>\n",
       "      <td>(0, 1)\\t5.67887358727\\n  (0, 2)\\t5.67887358727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>Horror|Sci-Fi|Romance</td>\n",
       "      <td>[horror, sci-fi, romance]</td>\n",
       "      <td>(0, 1)\\t5.67887358727\\n  (0, 2)\\t5.678873587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>Sci-Fi|Comedy</td>\n",
       "      <td>[sci-fi, comedy]</td>\n",
       "      <td>(0, 0)\\t2.09590327429\\n  (0, 3)\\t5.67887358727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                 genres                     tokens  \\\n",
       "0      123         Horror|Romance          [horror, romance]   \n",
       "1      456  Horror|Sci-Fi|Romance  [horror, sci-fi, romance]   \n",
       "2      666          Sci-Fi|Comedy           [sci-fi, comedy]   \n",
       "\n",
       "                                            features  \n",
       "0     (0, 1)\\t5.67887358727\\n  (0, 2)\\t5.67887358727  \n",
       "1    (0, 1)\\t5.67887358727\\n  (0, 2)\\t5.678873587...  \n",
       "2     (0, 0)\\t2.09590327429\\n  (0, 3)\\t5.67887358727  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.32192809  3.32192809  0.        ]\n",
      " [ 0.          0.          3.32192809]]\n"
     ]
    }
   ],
   "source": [
    "movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "movies = tokenize(movies)\n",
    "tf = []\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "max_k = defaultdict()\n",
    "df = dict()\n",
    "genres = movies['tokens']\n",
    "a = []\n",
    "dfd = []\n",
    "#ids = movies['movieId']\n",
    "flat = list(set([item for sublist in genres for item in sublist]))\n",
    "#ctr = Counter(flat)\n",
    "#count = 0\n",
    "#df = dict(ctr)\n",
    "#print(df['sci-fi'])\n",
    "N = len(movies)\n",
    "x = []\n",
    "genres = list(genres)\n",
    "for g in genres:\n",
    "    for f in flat:\n",
    "        if f in g:\n",
    "            x.append(f)\n",
    "            \n",
    "#abc = Counter(x)\n",
    "df = dict(Counter(x))\n",
    "#print(df['horror'])       \n",
    "\n",
    "\n",
    "for g in sorted(list(genres)):\n",
    "    c = Counter(g)\n",
    "    tf = dict(c)\n",
    "#    print(tf.keys())\n",
    "    max_k = tf[max(tf.keys())]\n",
    "    unique = sorted(list(set(g)))\n",
    "    for x in unique:\n",
    "        nr = tf[x]\n",
    "        dr = max_k * np.log10(N/df[x])\n",
    "#        dr = 1\n",
    "#        print(dr)\n",
    "        index = vocabulary.setdefault(x, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(nr/dr)\n",
    "    indptr.append(len(indices))\n",
    "csr = csr_matrix((data, indices, indptr))\n",
    "print(csr.toarray())    \n",
    "\n",
    "\n",
    "#xyz = movies['features'].as_matrix\n",
    "#print(xyz)\n",
    "#print(movies.as_matrix(columns=movies.columns[3:]))\n",
    "#print(sorted(vocabulary.items()))\n",
    "    #movies['features'] = csr\n",
    "    \n",
    "#print(movies['features'])\n",
    "#    movies['features'] = csr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    a = np.array(a.toarray())\n",
    "    b = np.array(b.toarray())\n",
    "    dr_a = np.linalg.norm(a)\n",
    "    dr_b = np.linalg.norm(b)\n",
    "    return(np.dot(a,b.T)/dr_a*dr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "    \n",
    "#        nr = tfs[key]\n",
    "#        dr = df[key]\n",
    "#        print(nr)\n",
    "#        print(dr)\n",
    "    \n",
    "#    max_k = tf[max(tf.keys())]\n",
    "#    for i in range(len(g)):\n",
    "\n",
    "#    c = Counter(g)\n",
    "#    tf = dict(c)\n",
    "    \n",
    "#    max_k = tf[max(tf.keys())]\n",
    "#for g in genres:\n",
    "#    tf[genres.count(g)] = genres.count(g)\n",
    "#    c = Counter(g)\n",
    "#    tf = c\n",
    "#    keys.append(c.keys())\n",
    "#    vals.append(c.values())\n",
    "\n",
    "\n",
    "#for k,v in keys,vals:\n",
    "#    tf[k] = v\n",
    "    \n",
    "#print(tf)\n",
    "#    vals.append(Counter(g))\n",
    "#for v in vals:\n",
    "#    print(v.keys())\n",
    "#    flat = [item for sublist in genres for item in sublist]\n",
    "#    print(flat)\n",
    "#for g in genres:\n",
    "#    tf.append(Counter(g))\n",
    "#for t in tf:\n",
    "#    print(list(t.values()))\n",
    "#    print(max(t.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    \"\"\"DONE.\n",
    "    Returns a random split of the ratings matrix into a training and testing set.\n",
    "    \"\"\"\n",
    "    test = set(range(len(ratings))[::1000])\n",
    "    train = sorted(set(range(len(ratings))) - test)\n",
    "    test = sorted(test)\n",
    "    return ratings.iloc[train], ratings.iloc[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_predictions(movies, ratings_train, ratings_test):\n",
    "    predicted = []\n",
    "    all_ratings = []\n",
    "    nr = 0\n",
    "    dr = 0\n",
    "    for uid,mid in zip(ratings_test['userId'], ratings_test['movieId']):\n",
    "        a = movies['features'][movies[movies.movieId==mid].index[0]]\n",
    "        for x,train in ratings_train[ratings_train.userId==uid].iterrows():\n",
    "            b = movies['features'][movies[movies.movieId==train.movieId].index[0]]\n",
    "            rate = train.rating\n",
    "            all_ratings.append(rate)\n",
    "            cos = cosine_sim(a, b)\n",
    "            if cos.all() > 0:\n",
    "                dr = dr + cos\n",
    "                nr = nr + (cos*rate)\n",
    "        if nr <= 0 and dr <= 0:\n",
    "            predicted.append(sum(all_ratings) / float(len(all_ratings)))\n",
    "        else:\n",
    "            predicted.append(nr/dr)            \n",
    "            \n",
    "    return (np.array(final_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    \"\"\" DONE. Download and unzip data.\n",
    "    \"\"\"\n",
    "    url = 'https://www.dropbox.com/s/h9ubx22ftdkyvd5/ml-latest-small.zip?dl=1'\n",
    "    urllib.request.urlretrieve(url, 'ml-latest-small.zip')\n",
    "    zfile = zipfile.ZipFile('ml-latest-small.zip')\n",
    "    zfile.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                        NaN\n",
      "1      (0, 2)\\t3.32192809489\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "movies = tokenize(movies)\n",
    "movies,vocab = featurize(movies)\n",
    "#b = movies['features'][movies[movies.movieId==456].index[0]]\n",
    "b = movies.where(movies.movieId==456)\n",
    "print(b['features'])\n",
    "#c = movies['features'][movies[movies.movieId==123].index[0]]\n",
    "#b = np.array(b.toarray())\n",
    "#c = np.array(c.toarray())\n",
    "#x1 = b.dot(c.T)\n",
    "#print(cosine_sim(b,c))\n",
    "\n",
    "#x1 = np.linalg.norm(b)\n",
    "#x2 = np.linalg.norm(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to literal (<ipython-input-98-bcb4855e36fe>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-bcb4855e36fe>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x = 0, y = 0\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to literal\n"
     ]
    }
   ],
   "source": [
    "x = 0, y = 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-91559441ffb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ml-latest-small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_data' is not defined"
     ]
    }
   ],
   "source": [
    "download_data()\n",
    "path = 'ml-latest-small'\n",
    "ratings = pd.read_csv(path + os.path.sep + 'ratings.csv')\n",
    "movies = pd.read_csv(path + os.path.sep + 'movies.csv')\n",
    "movies = tokenize(movies)\n",
    "movies, vocab = featurize(movies)\n",
    "print('vocab:')\n",
    "print(sorted(vocab.items())[:10])\n",
    "ratings_train, ratings_test = train_test_split(ratings)\n",
    "print('%d training ratings; %d testing ratings' % (len(ratings_train), len(ratings_test)))\n",
    "predictions = make_predictions(movies, ratings_train, ratings_test)\n",
    "#print('error=%f' % mean_absolute_error(predictions, ratings_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
